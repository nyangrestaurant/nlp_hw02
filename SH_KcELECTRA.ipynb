{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhpCIij5JHE7"
   },
   "source": [
    "Last Update @ 2021.07.22\n",
    "\n",
    "- Fix typo (training_epoch_endÎäî ÏïÑÎ¨¥Í≤ÉÎèÑ Î∞òÌôòÌïòÏßÄ ÏïäÏïÑÏïº Ìï®)\n",
    "\n",
    "\n",
    "Update @ 2021.06.30\n",
    "\n",
    "- Fix typo (train_epoch_end -> training_epoch_end)\n",
    "\n",
    "Update @ 2021.05.12\n",
    "\n",
    "- PyTorch-Lightning v1.3.0 Í≥µÏãù  Î¶¥Î¶¨Ï¶à \n",
    "- Inference code (load ckpt) Ï∂îÍ∞Ä  \n",
    "\n",
    "Update @ 2021.04.07\n",
    "\n",
    "- KcELECTRA Î∞è AutoModel Ï∂îÍ∞Ä\n",
    "- Î∂àÌïÑÏöîÌïú warning Ïú†Î∞ú ÏΩîÎìú Ï†úÍ±∞(Logging)\n",
    "\n",
    "Update @ 2021.03.16. \n",
    "\n",
    "- PyTorch-Lightning v1.3.0 Î∞òÏòÅ\n",
    "\n",
    "\n",
    "Update @ 2020.12.04\n",
    "\n",
    "- Huggingface Transformers 4.0.0  Î≤ÑÏ†Ñ Î∞òÏòÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGAdyjAdF0kd"
   },
   "source": [
    "# Package ÏÑ§Ïπò & Îç∞Ïù¥ÌÑ∞ Î∞õÍ∏∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEpMfnEtfYMq"
   },
   "source": [
    "## PyTorch-Lightning & Transformers\n",
    "\n",
    "PyTorchÏûêÏ≤¥ Ïô∏ Îã§Î•∏ ÎùºÏù¥Î∏åÎü¨Î¶¨Îì§ÏùÄ Í∏∞Ï°¥Í≥º ÎèôÏùºÌïòÍ≤å ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vx2mHvhGFYBp"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers, emoji, soynlp, pytorch_lightning\n",
    "except:\n",
    "    !pip install -U -q transformers emoji soynlp pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnh-RRPeyYcF",
    "outputId": "a20c3e85-7a7b-423d-d4e1-a7be4b1be09f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.8/dist-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "pip install emoji==1.7.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iKK-Y9a3F6vr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./nsmc'):\n",
    "    !git clone https://github.com/e9t/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYE7t_UNGiGO",
    "outputId": "8224e4dc-521f-4652-8ba7-ce57e4582fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tdocument\tlabel\n",
      "9976970\tÏïÑ ÎçîÎπô.. ÏßÑÏßú ÏßúÏ¶ùÎÇòÎÑ§Ïöî Î™©ÏÜåÎ¶¨\t0\n",
      "3819312\tÌù†...Ìè¨Ïä§ÌÑ∞Î≥¥Í≥† Ï¥àÎî©ÏòÅÌôîÏ§Ñ....Ïò§Î≤ÑÏó∞Í∏∞Ï°∞Ï∞® Í∞ÄÎ≥çÏßÄ ÏïäÍµ¨ÎÇò\t1\n",
      "10265843\tÎÑàÎ¨¥Ïû¨Î∞ìÏóàÎã§Í∑∏ÎûòÏÑúÎ≥¥ÎäîÍ≤ÉÏùÑÏ∂îÏ≤úÌïúÎã§\t0\n",
      "9045019\tÍµêÎèÑÏÜå Ïù¥ÏïºÍ∏∞Íµ¨Î®º ..ÏÜîÏßÅÌûà Ïû¨ÎØ∏Îäî ÏóÜÎã§..ÌèâÏ†ê Ï°∞Ï†ï\t0\n",
      "6483659\tÏÇ¨Ïù¥Î™¨ÌéòÍ∑∏Ïùò ÏùµÏÇ¥Ïä§Îü∞ Ïó∞Í∏∞Í∞Ä ÎèãÎ≥¥ÏòÄÎçò ÏòÅÌôî!Ïä§ÌååÏù¥ÎçîÎß®ÏóêÏÑú ÎäôÏñ¥Î≥¥Ïù¥Í∏∞Îßå ÌñàÎçò Ïª§Ïä§Ìã¥ ÎçòÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ÎÇòÎèÑ Ïù¥ÎªêÎ≥¥ÏòÄÎã§\t1\n",
      "5403919\tÎßâ Í±∏ÏùåÎßà ÎóÄ 3ÏÑ∏Î∂ÄÌÑ∞ Ï¥àÎì±ÌïôÍµê 1ÌïôÎÖÑÏÉùÏù∏ 8ÏÇ¥Ïö©ÏòÅÌôî.„Öã„Öã„Öã...Î≥ÑÎ∞òÍ∞úÎèÑ ÏïÑÍπåÏõÄ.\t0\n",
      "7797314\tÏõêÏûëÏùò Í∏¥Ïû•Í∞êÏùÑ Ï†úÎåÄÎ°ú ÏÇ¥Î†§ÎÇ¥ÏßÄÎ™ªÌñàÎã§.\t0\n",
      "9443947\tÎ≥Ñ Î∞òÍ∞úÎèÑ ÏïÑÍπùÎã§ ÏöïÎÇòÏò®Îã§ Ïù¥ÏùëÍ≤Ω Í∏∏Ïö©Ïö∞ Ïó∞Í∏∞ÏÉùÌôúÏù¥Î™áÎÖÑÏù∏ÏßÄ..Ï†ïÎßê Î∞úÎ°úÌï¥ÎèÑ Í∑∏Í≤ÉÎ≥¥Îã® ÎÇ´Í≤üÎã§ ÎÇ©Ïπò.Í∞êÍ∏àÎßåÎ∞òÎ≥µÎ∞òÎ≥µ..Ïù¥ÎìúÎùºÎßàÎäî Í∞ÄÏ°±ÎèÑÏóÜÎã§ Ïó∞Í∏∞Î™ªÌïòÎäîÏÇ¨ÎûåÎßåÎ™®ÏóøÎÑ§\t0\n",
      "7156791\tÏï°ÏÖòÏù¥ ÏóÜÎäîÎç∞ÎèÑ Ïû¨ÎØ∏ ÏûàÎäî Î™áÏïàÎêòÎäî ÏòÅÌôî\t1\n"
     ]
    }
   ],
   "source": [
    "!head nsmc/ratings_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLh_ziVCHwkH"
   },
   "source": [
    "# Ìå®ÌÇ§ÏßÄ import & Í∏∞Î≥∏ Args ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Yb0113DUFE1k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dN1zqYeKH2JZ"
   },
   "source": [
    "## Í∏∞Î≥∏ ÌïôÏäµ Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fPr2_vTPFuP0"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'random_seed': 42, # Random Seed\n",
    "    'pretrained_model': 'beomi/KcELECTRA-base',  # Transformers PLM name\n",
    "    'pretrained_tokenizer': '',  # Optional, Transformers Tokenizer Name. Overrides `pretrained_model`\n",
    "    'batch_size': 32,\n",
    "    'lr': 5e-6,  # Starting Learning Rate\n",
    "    'epochs': 1,  # Max Epochs\n",
    "    'max_length': 150,  # Max Length input size\n",
    "    'train_data_path': \"nsmc/ratings_train.txt\",  # Train Dataset file \n",
    "    'val_data_path': \"nsmc/ratings_test.txt\",  # Validation Dataset file \n",
    "    'test_mode': False,  # Test Mode enables `fast_dev_run`\n",
    "    'optimizer': 'AdamW',  # AdamW vs AdamP\n",
    "    'lr_scheduler': 'exp',  # ExponentialLR vs CosineAnnealingWarmRestarts\n",
    "    'fp16': True,  # Enable train on FP16(if GPU)\n",
    "    'tpu_cores': 0,  # Enable TPU with 1 core or 8 cores\n",
    "    'cpu_workers': os.cpu_count(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23Nf_fc9sesX",
    "outputId": "49121692-76ea-4ff8-973c-c0fa7e9067c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_seed': 42,\n",
       " 'pretrained_model': 'beomi/KcELECTRA-base',\n",
       " 'pretrained_tokenizer': '',\n",
       " 'batch_size': 32,\n",
       " 'lr': 5e-06,\n",
       " 'epochs': 1,\n",
       " 'max_length': 150,\n",
       " 'train_data_path': 'nsmc/ratings_train.txt',\n",
       " 'val_data_path': 'nsmc/ratings_test.txt',\n",
       " 'test_mode': False,\n",
       " 'optimizer': 'AdamW',\n",
       " 'lr_scheduler': 'exp',\n",
       " 'fp16': True,\n",
       " 'tpu_cores': 0,\n",
       " 'cpu_workers': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2AcwMYa3nmd"
   },
   "source": [
    "# Model ÎßåÎì§Í∏∞ with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wB0_CaIuLtBB",
    "outputId": "380dc66d-42c5-4cfa-b7ca-88a2f62f114a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 30 02:09:13 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ImupuGXDGq7b"
   },
   "outputs": [],
   "source": [
    "class Model(LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() # Ïù¥ Î∂ÄÎ∂ÑÏóêÏÑú self.hparamsÏóê ÏúÑ kwargsÍ∞Ä Ï†ÄÏû•ÎêúÎã§.\n",
    "        \n",
    "        self.clsfier = AutoModelForSequenceClassification.from_pretrained(self.hparams.pretrained_model)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.hparams.pretrained_tokenizer\n",
    "            if self.hparams.pretrained_tokenizer\n",
    "            else self.hparams.pretrained_model\n",
    "        )\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        return self.clsfier(**kwargs)\n",
    "\n",
    "    def step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        output = self(input_ids=data, labels=labels)\n",
    "\n",
    "        # Transformers 4.0.0+\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        y_true = list(labels.cpu().numpy())\n",
    "        y_pred = list(preds.cpu().numpy())\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx)\n",
    "\n",
    "    def epoch_end(self, outputs, state='train'):\n",
    "        loss = torch.tensor(0, dtype=torch.float)\n",
    "        for i in outputs:\n",
    "            loss += i['loss'].cpu().detach()\n",
    "        loss = loss / len(outputs)\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for i in outputs:\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        self.log(state+'_loss', float(loss), on_epoch=True, prog_bar=True)\n",
    "        self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n",
    "        self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n",
    "        self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n",
    "        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Loss: {loss}, Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.epoch_end(outputs, state='train')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.epoch_end(outputs, state='val')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer == 'AdamW':\n",
    "            optimizer = AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        elif self.hparams.optimizer == 'AdamP':\n",
    "            from adamp import AdamP\n",
    "            optimizer = AdamP(self.parameters(), lr=self.hparams.lr)\n",
    "        else:\n",
    "            raise NotImplementedError('Only AdamW and AdamP is Supported!')\n",
    "        if self.hparams.lr_scheduler == 'cos':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n",
    "        elif self.hparams.lr_scheduler == 'exp':\n",
    "            scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
    "        else:\n",
    "            raise NotImplementedError('Only cos and exp lr scheduler is Supported!')\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "        }\n",
    "\n",
    "    def read_data(self, path):\n",
    "        if path.endswith('xlsx'):\n",
    "            return pd.read_excel(path)\n",
    "        elif path.endswith('csv'):\n",
    "            return pd.read_csv(path)\n",
    "        elif path.endswith('tsv') or path.endswith('txt'):\n",
    "            return pd.read_csv(path, sep='\\t')\n",
    "        else:\n",
    "            raise NotImplementedError('Only Excel(xlsx)/Csv/Tsv(txt) are Supported')\n",
    "\n",
    "    def clean(self, x):\n",
    "        emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n",
    "        #emojis = ''.join(emoji.EMOJI_DATAas.keys())\n",
    "        \n",
    "        pattern = re.compile(f'[^ .,?!/@$%~ÔºÖ¬∑‚àº()\\x00-\\x7F„Ñ±-Ìû£{emojis}]+')\n",
    "        url_pattern = re.compile(\n",
    "            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "        x = pattern.sub(' ', x)\n",
    "        x = url_pattern.sub('', x)\n",
    "        x = x.strip()\n",
    "        x = repeat_normalize(x, num_repeats=2)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x, **kwargs):\n",
    "        return self.tokenizer.encode(\n",
    "            self.clean(str(x)),\n",
    "            padding='max_length',\n",
    "            max_length=self.hparams.max_length,\n",
    "            truncation=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def preprocess_dataframe(self, df):\n",
    "        df['document'] = df['document'].map(self.encode)\n",
    "        return df\n",
    "\n",
    "    def dataloader(self, path, shuffle=False):\n",
    "        df = self.read_data(path)\n",
    "        df = self.preprocess_dataframe(df)\n",
    "\n",
    "        dataset = TensorDataset(\n",
    "            torch.tensor(df['document'].to_list(), dtype=torch.long),\n",
    "            torch.tensor(df['label'].to_list(), dtype=torch.long),\n",
    "        )\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size * 1 if not self.hparams.tpu_cores else self.hparams.tpu_cores,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=self.hparams.cpu_workers,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.dataloader(self.hparams.train_data_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.dataloader(self.hparams.val_data_path, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_FteKzZ67cyj"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename='epoch{epoch}-val_acc{val_acc:.4f}',\n",
    "    monitor='val_acc',\n",
    "    save_top_k=3,\n",
    "    mode='max',\n",
    "    auto_insert_metric_name=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBsvcdxySCqd"
   },
   "source": [
    "# ÌïôÏäµ!\n",
    "\n",
    "> üí°**NOTE**üí° 1epochÎ≥ÑÎ°ú GPU P100Í∏∞Ï§Ä ÏïΩ50Î∂Ñ, GPU V100Í∏∞Ï§Ä ~15Î∂ÑÏù¥ Í±∏Î¶ΩÎãàÎã§. <br>\n",
    "> ÌïôÏäµÏãú ÏïΩ 0.92 Ïù¥ÌïòÏùò validation accÎ•º ÏñªÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "> Update @ 2020.09.01\n",
    "> ÏµúÍ∑º Colab ProÏóêÏÑú V100Ïù¥ Î∞∞Ï†ïÎê©ÎãàÎã§.\n",
    "\n",
    "```python\n",
    "# 1epoch\n",
    "loss=0.207, v_num=0, val_loss=0.221, val_acc=0.913, val_precision=0.914, val_recall=0.913, val_f1=0.914\n",
    "# 2epoch\n",
    "loss=0.152, v_num=0, val_loss=0.213, val_acc=0.918, val_precision=0.912, val_recall=0.926, val_f1=0.919\n",
    "# 3epoch\n",
    "loss=0.135, v_num=0, val_loss=0.225, val_acc=0.919, val_precision=0.907, val_recall=0.936, val_f1=0.921\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBT5GzYn8a4W",
    "outputId": "e9738f66-df2a-4121-ecef-dfbd2bc69cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 30 02:09:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   61C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690,
     "referenced_widgets": [
      "8202779479a943e7b57dec08a65262dd",
      "9fa83cb14d8940579221390fb58d08f5",
      "4f657eafe0814caa8d64c2c2d2ef0036",
      "132eeaf162fa4e03b0be9a220dba3aaf",
      "31632661fc3d4b62b9c809f025505b30",
      "9ef92d724e0145aab3386b223f94ee47",
      "56efcd61f1cf45ac838e63706a1db0e3",
      "0d07cc5230cb4da1b964be87f433baff",
      "91bfbf50fd0f49df85a905dd6b7329df",
      "97337aa3b4d14e47bd9f1ff8e11bc2db",
      "d2519a217cf44cf488b578a2b53f5179",
      "25282895bae647339d3bde539d2a8d01",
      "8d5a61e4f8af44578e315e955b74225f",
      "38ff74b41e53420c84c9d2ce66c9b43b",
      "2d3bbf2df4044f99ad7e047631e51358",
      "e3932528d1f5403fbddc18f0078eb775",
      "6e03e4400f4347b3b8ef517355a10458",
      "81c48ed36cd1414d9e37d42273b615ba",
      "a9425d62b73f4682a537149fd286a81c",
      "431f71eee5d149298e68c4623dc3059a",
      "db9e40988bd64fe68dbf465531335ff5",
      "0494f8cd931244d792c53bec5fa0c398"
     ]
    },
    "id": "qu1QkSZsHo8x",
    "outputId": "e25c5d92-cd63-47b6-e3f1-3d9ca27955c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_lite.utilities.seed:Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch Ver 1.13.0+cu116\n",
      "Fix Seed: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n",
      "  rank_zero_deprecation(\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Start Training ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/optimizer.py:382: RuntimeWarning: Found unsupported keys in the optimizer configuration: {'scheduler'}\n",
      "  rank_zero_warn(\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name    | Type                             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | clsfier | ElectraForSequenceClassification | 124 M \n",
      "-------------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "249.093   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8202779479a943e7b57dec08a65262dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25282895bae647339d3bde539d2a8d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 VAL] Loss: 0.22389431297779083, Acc: 0.9101, Prec: 0.8926699582225598, Rec: 0.933698804274421, F1: 0.9127235306681165\n",
      "[Epoch 0 TRAIN] Loss: 0.2758503258228302, Acc: 0.88338, Prec: 0.8823592178621922, Rec: 0.8840926403570903, F1: 0.8832250786042817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "print(\"Using PyTorch Ver\", torch.__version__)\n",
    "print(\"Fix Seed:\", args['random_seed'])\n",
    "seed_everything(args['random_seed'])\n",
    "model = Model(**args)\n",
    "\n",
    "print(\":: Start Training ::\")\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=args['epochs'],\n",
    "    fast_dev_run=args['test_mode'],\n",
    "    num_sanity_val_steps=None if args['test_mode'] else 0,\n",
    "    # For GPU Setup\n",
    "    deterministic=torch.cuda.is_available(),\n",
    "    gpus=[0] if torch.cuda.is_available() else None,  # 0Î≤à idx GPU  ÏÇ¨Ïö©\n",
    "    precision=16 if args['fp16'] and torch.cuda.is_available() else 32,\n",
    "    # For TPU Setup\n",
    "    # tpu_cores=args['tpu_cores'] if args['tpu_cores'] else None,\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyczos82ept3"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8mdp3SK2etM-",
    "outputId": "90477d4f-8863-492e-aee5-34368f094716"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./lightning_logs/version_2/checkpoints/epoch0-val_acc0.9101.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "#latest_ckpt = sorted(glob('./lightning_logs/version_0/checkpoints/*.ckpt'))[-1]\n",
    "latest_ckpt = sorted(glob('./lightning_logs/version_2/checkpoints/*.ckpt'))[-1]\n",
    "latest_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOMT9Ublj_1G",
    "outputId": "37628165-1402-4a53-889e-a7c51620272c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Model.load_from_checkpoint(latest_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DqlCK83Je8JL"
   },
   "outputs": [],
   "source": [
    "def infer(x):\n",
    "    return torch.softmax(\n",
    "        model(**model.tokenizer(x, return_tensors='pt')\n",
    "    ).logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feoKN8OWfB86",
    "outputId": "e127f0e6-6352-4a94-de62-c668ca9f387c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9282, 0.0718]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('Ïù¥ ÏòÅÌôî ÎÖ∏Ïûº „Ö°„Ö°')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrj1RyeSfFLf",
    "outputId": "b617b7f7-d50c-429c-922c-19c0092e2da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2015, 0.7985]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('Ïù¥  ÏòÅÌôî  ÍøÄÏûº! ÏôÑÏ°¥  Ï∂îÏ≤úÏöî  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whZpnxBtfHhv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0494f8cd931244d792c53bec5fa0c398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d07cc5230cb4da1b964be87f433baff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "132eeaf162fa4e03b0be9a220dba3aaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97337aa3b4d14e47bd9f1ff8e11bc2db",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d2519a217cf44cf488b578a2b53f5179",
      "value": " 6251/6251 [23:23&lt;00:00,  4.45it/s, loss=0.232, v_num=2, val_loss=0.224, val_acc=0.910, val_precision=0.893, val_recall=0.934, val_f1=0.913, train_loss=0.276, train_acc=0.883, train_precision=0.882, train_recall=0.884, train_f1=0.883]"
     }
    },
    "25282895bae647339d3bde539d2a8d01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d5a61e4f8af44578e315e955b74225f",
       "IPY_MODEL_38ff74b41e53420c84c9d2ce66c9b43b",
       "IPY_MODEL_2d3bbf2df4044f99ad7e047631e51358"
      ],
      "layout": "IPY_MODEL_e3932528d1f5403fbddc18f0078eb775"
     }
    },
    "2d3bbf2df4044f99ad7e047631e51358": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db9e40988bd64fe68dbf465531335ff5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0494f8cd931244d792c53bec5fa0c398",
      "value": " 1563/1563 [02:07&lt;00:00, 12.28it/s]"
     }
    },
    "31632661fc3d4b62b9c809f025505b30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "38ff74b41e53420c84c9d2ce66c9b43b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9425d62b73f4682a537149fd286a81c",
      "max": 1563,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_431f71eee5d149298e68c4623dc3059a",
      "value": 1563
     }
    },
    "431f71eee5d149298e68c4623dc3059a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f657eafe0814caa8d64c2c2d2ef0036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d07cc5230cb4da1b964be87f433baff",
      "max": 6251,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91bfbf50fd0f49df85a905dd6b7329df",
      "value": 6251
     }
    },
    "56efcd61f1cf45ac838e63706a1db0e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e03e4400f4347b3b8ef517355a10458": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81c48ed36cd1414d9e37d42273b615ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8202779479a943e7b57dec08a65262dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fa83cb14d8940579221390fb58d08f5",
       "IPY_MODEL_4f657eafe0814caa8d64c2c2d2ef0036",
       "IPY_MODEL_132eeaf162fa4e03b0be9a220dba3aaf"
      ],
      "layout": "IPY_MODEL_31632661fc3d4b62b9c809f025505b30"
     }
    },
    "8d5a61e4f8af44578e315e955b74225f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e03e4400f4347b3b8ef517355a10458",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_81c48ed36cd1414d9e37d42273b615ba",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "91bfbf50fd0f49df85a905dd6b7329df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97337aa3b4d14e47bd9f1ff8e11bc2db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ef92d724e0145aab3386b223f94ee47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fa83cb14d8940579221390fb58d08f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ef92d724e0145aab3386b223f94ee47",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_56efcd61f1cf45ac838e63706a1db0e3",
      "value": "Epoch 0: 100%"
     }
    },
    "a9425d62b73f4682a537149fd286a81c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2519a217cf44cf488b578a2b53f5179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db9e40988bd64fe68dbf465531335ff5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3932528d1f5403fbddc18f0078eb775": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
